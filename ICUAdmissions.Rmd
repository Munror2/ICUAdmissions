---
title: "ICUAdmissionsFinal"
author: "Glenne Grossman, Viorica Lefter, Robyn Munro, Karishini Ramamoorthi, Elizabeth Warnick"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document: 
    number_sections: TRUE
    code_folding: hide
    toc: yes
    toc_float: 
      toc_collapsed: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(Rcmdr)
library(car)
library(RcmdrMisc)
library (ggplot2)
library (sjPlot)
library (multcomp)
library (multcompView)
library (DescTools)
library (tidyr)
library(rsample, pos=21)
library(sjstats)
library(ggplot2, pos=18)
library(sjPlot, pos=19)
library(randomForest, pos=20)
library(tidyr, pos=21)
library(rsample, pos=21)
library(DT, pos=23)
library(dplyr)
library(jtools)

library(magrittr)
library(RcmdrMisc)
library(Rcmdr)
library(kableExtra)
library(sjlabelled)
library(sjmisc)
library(devtools)
devtools::install_github("strengejacke/strengejacke")
library(strengejacke)
library(sjPlot)
library(sjstats, pos=22)
library(ggplot2)
library(qwraps2)
library(gplots)
library(data.table)
library(tidyverse)
library(kableExtra)
library(ggthemes)
library(sjPlot)
library(sjlabelled)
library(sjmisc)
library(ggplot2)
library(Rcmdr)
library(car)
library(RcmdrMisc)
library (ggplot2)
library (sjPlot)
library (multcomp)
library (multcompView)
library (DescTools)
library (tidyr)

icu <- read.table("icu_factored.csv", header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)

icu <- within(icu, {
  Consciousness <- 
  factor(Consciousness, 
  labels=c('Conscious',
  'Unconscious', 'Unconscious'))
})
```

#Executive Summary

#Introduction

#Methodology

#Analysis
##Introduction to the Dataset
###Demographics
###Admissions
###Clinical

##Predictive Model

```{r echo=FALSE, message=FALSE, warning=FALSE}
DemographicModel <- glm(Status ~ Age + 
  + Race  + Sex , family=binomial(logit), 
  data=icu)

tab_model(DemographicModel)


 plot_model(DemographicModel, show.values=TRUE, value.offset = .3)
 
 ##lets look at just age
```
```{r echo=FALSE, message=FALSE, warning=FALSE}
DemographicModel <- glm(Status ~ Age, family=binomial(logit), 
  data=icu)

tab_model(DemographicModel)


 plot_model(DemographicModel, show.values=TRUE, value.offset = .3)
 
 
```



```{r echo=FALSE, message=FALSE, warning=FALSE}
AdmissionsModel <- glm(Status ~   Consciousness + CPR + 
   + Previous + Service + Type, family=binomial(logit), 
  data=icu)

tab_model(AdmissionsModel)


 plot_model(AdmissionsModel, show.values=TRUE, value.offset = .3)
 
 ##From this we keep Consciousness and Type
```
```{r echo=FALSE, message=FALSE, warning=FALSE}
AdmissionsModel2 <- glm(Status ~   Consciousness + 
    Type, family=binomial(logit), 
  data=icu)

tab_model(AdmissionsModel2)


 plot_model(AdmissionsModel2, show.values=TRUE, value.offset = .3)
 
 ##Still both significant
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
ClinicalModel <- glm(Status ~  Bicarbonate + Cancer +  
  Creatinine + Fracture + HeartRate + Infection + PCO2 + PH + PO2 + Renal  +  Systolic , family=binomial(logit), 
  data=icu)

tab_model(ClinicalModel)


 plot_model(ClinicalModel, show.values=TRUE, value.offset = .3)
 
 ##From this we keep Systolic
```
```{r echo=FALSE, message=FALSE, warning=FALSE}
ClinicalModel2 <- glm(Status ~    Systolic , family=binomial(logit), 
  data=icu)

tab_model(ClinicalModel2)


 plot_model(ClinicalModel2, show.values=TRUE, value.offset = .3)
 
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
FullModel <- glm(Status ~ Age + Bicarbonate + Cancer + Consciousness + CPR + 
  Creatinine + Fracture + HeartRate + Infection + PCO2 + PH + PO2 + Previous 
  + Race + Renal + Service + Sex + Systolic + Type, family=binomial(logit), 
  data=icu)

tab_model(FullModel)


 plot_model(FullModel, show.values=TRUE, value.offset = .3)
 
 ##From this we keep age Cancer and Consciousness and Type
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
FullModel2 <- glm(Status ~ Age  + Cancer + Consciousness +Type, family=binomial(logit), 
  data=icu)

tab_model(FullModel2)


 plot_model(FullModel2, show.values=TRUE, value.offset = .3)
 
 ##From this we keep age Cancer and Consciousness and Type
```

```{r echo=FALSE, warning=FALSE, message=FALSE, results=FALSE}
stepwise(FullModel, direction='forward/backward', criterion='BIC')
##doesn't get Cancer
```

```{r, echo=FALSE, message-FALSE, warning=FALSE, eval=FALSE}
icu <- within(icu, {fitted.GLM.7 <- fitted(GLM.7) 
})
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
set.seed(0)
train_test_split <- initial_split(icu, prop = 0.7)
train <- training(train_test_split)
test <- testing(train_test_split)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
Train <- glm(Status ~  Age + Type + Consciousness, 
  family=binomial(logit), data=train)
 
tab_model(Train)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
Train <- glm(Status ~  Age + Type + Consciousness, 
  family=binomial(logit), data=train)
 
tab_model(Train)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
predicted <- predict(Train, newdata=test  ) # # 
actual <- test$Status  # actual Intention to Return for the testing sample
x <- as.data.frame(cbind(actual, predicted))  
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
cor.test(x$actual,x$predicted) # hypothesis test for correlation
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(ggplot2)
ggplot(data=x, aes(x=predicted, y=actual)) + geom_jitter(width=0.15) + geom_smooth(method=lm)
actualvpredict <- lm(actual ~ predicted, x)
tab_model(actualvpredict)
```
_Robyns Regression Work Starts Here_

###Regression

```{r echo=FALSE, warning=FALSE, message=FALSE}
vif(lm(Status ~ Age + Bicarbonate + Cancer + Consciousness + CPR + 
  Creatinine + Fracture + HeartRate + Infection + PCO2 + PH + PO2 + Previous + Race + Renal + Service + Sex + Systolic + Type, data=icu))
```

MODEL 1: Vital Status vs. Age, Bicarbonate, Cancer, Consciousness, CPR, Creatinine, Fracture, HeartRate, Infection, PCO~2~, PH, PO~2~, Previous, Race, Renal, Service, Sex, Systolic, & Type

*Ho: None of the independent variables in the data set do not predict hospital mortality of ICU patients, based on information available at the time of ICU admissions.

*Ha: Some of the independent variables in the data set do predict hospital mortality of ICU patients, based on information available at the time of ICU admissions.

Table X.3. Logistic Regression of MODEL 1 using a Generalized Linear Model
```{r}
GLM.2 <- glm(Status ~ Age + Bicarbonate + Cancer + Consciousness + CPR + 
  Creatinine + Fracture + HeartRate + Infection + PCO2 + PH + PO2 + Previous 
  + Race + Renal + Service + Sex + Systolic + Type, family=binomial(logit), 
  data=icu)
summary(GLM.2)
exp(coef(GLM.2))  # Exponentiated coefficients ("odds ratios")
```

ANALYSIS OF MODEL 1

*Which independent variables in the data set are statistically significant in regard to predicting Vital Status?*

* In Table 4. the following independent variables are identified **statistically significant** at an alpha level of 0.05 in regard to prediting Vital Status of patients admitted to the ICU. The variables are listed in order of greatest signifiance to least significance, based on p-values:
    1.  CancerYes = 0.00189  
    2.  Age = 0.00225
    3.  TypeEmergency = 0.00523
    4.  ConsciousnessConscious = 0.00994
    5.  Systolic = 0.02732
* Null Deviance > Residual Deviance?
        + YES, decreases by 88 points, indicatig a good model.
* AIC Value = 156.17
* Confidence Intervals (see Table X.3):
    + None of the above five varialbes confidence intervals include 1, which indicates the variables are statistically significant. 
* ODDS Ratios:
    1.  CancerYes = 0.03072734
    2.  Age = 0.9451114 
    3.  TypeEmergency =  0.02356767
    4.  ConsciousnessConscious = 31.76531
    5.  Systolic = 1.021058

Therefore, we can state the predictor variables of CancerYes, Age, TypeEmergency, ConsciousnessConscious, and Systolic have a statistically significant relation with Vital Staus. Based of the above information, we reject the null hypothesis and state these five independent variables can be used to predict hospital mortality of ICU patients. Based on the odds ratios, Level of Consciousness at admission (no coma) is the greatest predictor of Vital Status. A patient admitted to the ICU is 31.7 times more likely to have a Vital Status = 0 (Lived) if they have a Consciousness Level = 0 (no coma).

ANALYSIS OF RUNNING A LOGISITC REGRESSION, ADDING ONE SIGNIFICANT VARIABLE AT A TIME TO COMPARE AIC SCORES

MODEL 2: Vital Status vs. CancerYes

Table X.4. Logistic Regression of MODEL 2
```{r echo=FALSE, warning=FALSE, message=FALSE}
GLM.3<- glm(Status ~ Cancer, family=binomial(logit), 
  data=icu)
summary(GLM.3)
exp(coef(GLM.3))  # Exponentiated coefficients ("odds ratios")
```


MODEL 3: Vital Status vs. CancerYes & Age

Table X.5. Logistic Regression of MODEL 3
```{r echo=FALSE, warning=FALSE, message=FALSE}
GLM.4<- glm(Status ~ Cancer + Age, family=binomial(logit), 
  data=icu)
summary(GLM.4)
exp(coef(GLM.4))  # Exponentiated coefficients ("odds ratios")
```

MODEL 4: Vital Status vs. CancerYes, Age & TypeEmergency

Table X.6. Logistic Regression of MODEL 4
```{r echo=FALSE, warning=FALSE, message=FALSE}
GLM.5<- glm(Status ~ Cancer + Age + Type, family=binomial(logit), 
  data=icu)
summary(GLM.5)
exp(coef(GLM.5))  # Exponentiated coefficients ("odds ratios")
```

MODEL 5: Vital Status vs. CancerYes, Age, TypeEmergency & ConsciousnessConscious

Table X.7. Logistic Regression of MODEL 5
```{r echo=FALSE, warning=FALSE, message=FALSE}
GLM.6<- glm(Status ~ Cancer + Age + Type + Consciousness, family=binomial(logit), 
  data=icu)
summary(GLM.6)
exp(coef(GLM.6))  # Exponentiated coefficients ("odds ratios")
```

MODEL 6: Vital Status vs. CancerYes, Age, TypeEmergency, ConsciousnessConscious & Systolic

Table X.8. Logistic Regression of MODEL 6
```{r echo=FALSE, warning=FALSE, message=FALSE}
GLM.7<- glm(Status ~ Cancer + Age + Type + Consciousness + Systolic, family=binomial(logit), 
  data=icu)
summary(GLM.7)
exp(coef(GLM.7))  # Exponentiated coefficients ("odds ratios")
```

BIC MODEL: Bayesian Information Criterion

* In statistics, the Bayesian information criterion (BIC) for model selection among a finite set of models. It is based, in part, on the likelihood function, and it is closely related to Akaike information criterion (AIC).

```{r echo=FALSE, warning=FALSE, message=FALSE}
stepwise(GLM.2, direction='forward/backward', criterion='BIC')
```

Table X.9. Comparison of AIC Scores from our Logistic Models

|MODELS     | AIC SCORE   |
|-----------|-------------|
| Model 1   | 156.17      |
| Model 2   | 204.16      |
| Model 3   | 198.29      |
| Model 4   | 177.13      |
| Model 5   | 146.59      |
| Model 6   | 142.44      |
| BIC Model | 142.4       |

ANALYSIS

* We completed our own linear regresssion using the five statistically significant variables identified by Model 1 of CancerYes, Age, TypeEmergency, ConsciousnessConscious & Systolic. We ran the Model 5 more times, adding one Independent Variable each time and assessing if the AIC score dropped (a lower AIC score indicates an improvement in the model). Our final Model 6 (will all five independent variables included) produced the lowest AIC score of 142.44. 
* We then verified our findings by using a Step-Wise Forward-Backward Bayesian Regression Model
    + The BIC model proved our Model 6 findings to be true because:
        + we achived the same AIC score of 142.4
        + the independent variables identified as significant (indicated by a minus sign) were the same.

> In conclusion, our logistic regression analysis leads us to find the best predictors of Vital Status for patients admitted to the ICU are: (1) CancerYes, (2) Age, (3) TypeEmergency, (4) ConsciousnessConscious, and (5) Systolic.

*Note: fitted values for Model 6 = predicted values
```{r echo=FALSE, warning=FALSE, message=FALSE}
icu <- within(icu, {fitted.GLM.7 <- fitted(GLM.7) 
})
```

> Setting up the Training and Testing Models

WHY USE TRAINING VS TESTING SAMPLES?

* Logistic regression models are trying to predict as well as possible.
* To better test how the model will work in reality, we train the model on 70% of the sample and hold 30% aside to test as “new” sample. We will predict values of the dependent variable in the “holdout” sample using the model built on the “training” sample.
* We will use the Regression on the findings from the training sample to predict group membership among those in the “testing” sample.
    + The training & test samples are kept separate so that we can objectively test the quality of the modeling and prediction.

Splitting the dataset into training sample (70%) and testing sample (30%).

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(rsample)
set.seed(0)
train_test_split <- initial_split(icu, prop = 0.7)
train <- training(train_test_split)
test <- testing(train_test_split)
```  

The training sample size is `r nrow(train)` and the testing sample size is `r nrow(test)`.


Prediction of the Training Model:

* The intent of this training model is to predict the mortality odds of a patient being diagnosed with a Vital Status = 1 (died) based on the informiation available at the time of ICU admission, specifically using the best predictor variables of CancerYes, Age, TypeEmergency, ConsciousnessConscious, & Systolic. If we have a good training model, we can make more detailed predictions. 

*Ho: CancerYes, Age, TypeEmergency, ConsciousnessConscious, & Systolic do not predict hospital mortality of ICU patients, based on information available at the time of ICU admissions.

*Ha: CancerYes, Age, TypeEmergency, ConsciousnessConscious, & Systolic do predict hospital mortality of ICU patients, based on information available at the time of ICU admissions.

Table X.11. Logistic Regression of Training Model
```{r echo=FALSE, warning=FALSE, message=FALSE}
GLM.Train <- glm(Status ~ Cancer + Age + Type + Consciousness + Systolic, 
  family=binomial(logit), data=train)
summary(GLM.Train)
exp(coef(GLM.Train))  
  # Exponentiated coefficients ("odds ratios")
tab_model(GLM.Train)
```

ANALYSIS OF TRAINING MODEL

* For the Training Model, Table X.11 identifies the following variables as **statistically significant** at an alpha level of 0.05 in regard to dpredict hospital mortality of ICU patients. The variables are listed in order of greatest signifiance to least based on p-values:
    1.  Consciousness(Conscious): smallest p-value of 0.00429 
    2.  Systolic: 0.00625
    3.  Age: 0.01196
    4.  Type(Emergency): 0.02396
    5.  Cancer(Yes): 0.03402

Table X.12. Comparison of Independent Varibables Identified as Statistically Significant in Model 6 and the Training Model
 
 Mod. 6 Statistically Sig. Variables |Training Model Statistically Sig. Variables|
|------------------------------------|------------------------------------|
| 1. *Type(Emergency)*               | 1. *Consciousness(Conscious)*      |
| 2. *Age*                           | 2. *Systolic*                      |
| 3. *Consciousness(Conscious)*      | 3. *Age*                           |
| 4. *Cancer(Yes)*                   | 4. *Type(Emergency)*               |
| 5. *Systolic*                      | 5. *Cancer(Yes)*                   |

Note: variables are listed for each model in order of decreasing statistical significance by p-value; 1 = most statistically significant (smallest p-value furtherest from a 0.05 Type 1 Error), 5 = least statisically significant (greatest p-value closest to 0.05 Type 1 Error)

* Null Deviance > Residual Deviance?
      + YES, decreases 60 points, indicating a good model.
* AIC Value = 99.766
      + The lowest AIC so far, a lower AIC value indicated an improvement in the model
* Confidence Intervals:
    + None of the confidence intervals include 1, which indicates the variables are statistically significant. 
* ODDS Ratios:
    1.  Consciousness(Conscious): 31.39354
    2.  Systolic: 1.030978
    3.  Age: 0.9600484 
    4.  Type(Emergency): 0.02455223  
    5.  Cancer(Yes): 0.05049618

The training model is an improvement upon our Model 6 Logisitic Regression Model as the significance of each variable based upon p-values aligns with the predictabilty of the odds ratios. In addition, our AIC value is the lowest at a value of 99.77. Based on the above information, we reject thhe null hypothesis and state CancerYes, Age, TypeEmergency, ConsciousnessConscious, & Systolic do predict hospital mortality of ICU patients, based on information available at the time of ICU admissions. Based on the odds ratios, Level of Consciousness at admission (no coma) is still the greatest predictor of Vital Status. A patient admitted to the ICU is 31.4 times more likely to have a Vital Status = 0 (Lived) if they have a Consciousness Level = 0 (no coma).


> Using the Training Model to Predict Our Testing Model

```{r echo=FALSE, warning=FALSE, message=FALSE}
test <- within(test, {
  fitted.GLM.Train <- fitted(GLM.Train)
  })
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
test <- within(test, {
  fitted_Statusrecode <- Recode(fitted.GLM.Train, '0:0.49 = "Lived"; 0.5:1 = "Died"', 
  as.factor=TRUE)
})
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
predicted <- test$fitted_Statusrecode
actual <- test$Status

x <- as.data.frame(cbind(actual, predicted))  

x$actual = factor(x$actual, levels = c(1,2), labels = c("Lived", "Died"))
x$predicted = factor(x$predicted, levels = c(1,2), labels = c("Lived", "Died"))
 
#datatable( x, filter="top", rownames = FALSE, options = list(pageLength = 10, scrollX=T ), colnames=c('Actual', 'Predicted'))
```


*Table X.14. Logistic Regression for Vital Status of Testing Model*
```{r echo=FALSE, warning=FALSE, message=FALSE}
GLM.Predicted <- glm(actual ~ predicted, 
  family=binomial(logit), data=test)
summary(GLM.Predicted)
```

*Table X.13. Comparing Actual and Predicted Values for Severity within the Testing Model*
```{r echo=FALSE, warning=FALSE, message=FALSE}
sjt.xtab(predicted, actual, show.row.prc = TRUE)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
 GLM.8 <- lm(actual ~ predicted, x)
```


CHANGE THIS FOR OUR DATA WHEN THE PROPER CHARTS ARE HERE!!!The regression of actual on predicted demonstrated a p value < 0.05,therefore rejct null hypothesis and conclude that predicted is significantly related to actual. However, the rsquared value of 0.391 indicates that only 39% of actuals can be attributed to predicted. This indicates that this model is not strong in predicting whether a tumour is malignant vs benign. 

#Key Findings

#Health System Reccomendations


